{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, json\n",
    "import torch, numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "from src.utils.extract_utils import get_mean_head_activations, compute_universal_function_vector\n",
    "from src.utils.intervention_utils import fv_intervention_natural_text, function_vector_intervention\n",
    "from src.utils.model_utils import load_gpt_model_and_tokenizer\n",
    "from src.utils.prompt_utils import load_dataset, word_pairs_to_prompt_data, create_prompt\n",
    "from src.utils.eval_utils import decode_to_vocab, sentence_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model & tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'EleutherAI/gpt-j-6b'\n",
    "model, tokenizer, model_config = load_gpt_model_and_tokenizer(model_name)\n",
    "EDIT_LAYER = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset and Compute task-conditioned mean activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('antonym', seed=0)\n",
    "mean_activations = get_mean_head_activations(dataset, model, model_config, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute function vector (FV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FV, top_heads = compute_universal_function_vector(mean_activations, model, model_config, n_top_heads=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Creation - ICL, Shuffled-Label, Zero-Shot, and Natural Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample ICL example pairs, and a test word\n",
    "dataset = load_dataset('antonym')\n",
    "word_pairs = dataset['train'][:5]\n",
    "test_pair = dataset['test'][21]\n",
    "\n",
    "prompt_data = word_pairs_to_prompt_data(word_pairs, query_target_pair=test_pair, prepend_bos_token=True)\n",
    "sentence = create_prompt(prompt_data)\n",
    "print(\"ICL prompt:\\n\", repr(sentence), '\\n\\n')\n",
    "\n",
    "shuffled_prompt_data = word_pairs_to_prompt_data(word_pairs, query_target_pair=test_pair, prepend_bos_token=True, shuffle_labels=True)\n",
    "shuffled_sentence = create_prompt(shuffled_prompt_data)\n",
    "print(\"Shuffled ICL Prompt:\\n\", repr(shuffled_sentence), '\\n\\n')\n",
    "\n",
    "zeroshot_prompt_data = word_pairs_to_prompt_data({'input':[], 'output':[]}, query_target_pair=test_pair, prepend_bos_token=True, shuffle_labels=True)\n",
    "zeroshot_sentence = create_prompt(zeroshot_prompt_data)\n",
    "print(\"Zero-Shot Prompt:\\n\", repr(zeroshot_sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean ICL Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check model's ICL answer\n",
    "clean_logits = sentence_eval(sentence, [test_pair['output']], model, tokenizer, compute_nll=False)\n",
    "\n",
    "print(\"Input Sentence:\", repr(sentence), '\\n')\n",
    "print(f\"Input Query: {repr(test_pair['input'])}, Target: {repr(test_pair['output'])}\\n\")\n",
    "print(\"ICL Prompt Top K Vocab Probs:\\n\", decode_to_vocab(clean_logits, tokenizer, k=5), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corrupted ICL Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform an intervention on the shuffled setting\n",
    "clean_logits, interv_logits = function_vector_intervention(shuffled_sentence, [test_pair['output']], EDIT_LAYER, FV, model, model_config, tokenizer)\n",
    "\n",
    "print(\"Input Sentence:\", repr(shuffled_sentence), '\\n')\n",
    "print(f\"Input Query: {repr(test_pair['input'])}, Target: {repr(test_pair['output'])}\\n\")\n",
    "print(\"Few-Shot-Shuffled Prompt Top K Vocab Probs:\\n\", decode_to_vocab(clean_logits, tokenizer, k=5), '\\n')\n",
    "print(\"Shuffled Prompt+FV Top K Vocab Probs:\\n\", decode_to_vocab(interv_logits, tokenizer, k=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-Shot Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intervention on the zero-shot prompt\n",
    "clean_logits, interv_logits = function_vector_intervention(zeroshot_sentence, [test_pair['output']], EDIT_LAYER, FV, model, model_config, tokenizer)\n",
    "\n",
    "print(\"Input Sentence:\", repr(zeroshot_sentence), '\\n')\n",
    "print(f\"Input Query: {repr(test_pair['input'])}, Target: {repr(test_pair['output'])}\\n\")\n",
    "print(\"Zero-Shot Top K Vocab Probs:\\n\", decode_to_vocab(clean_logits, tokenizer, k=5), '\\n')\n",
    "print(\"Zero-Shot+FV Vocab Top K Vocab Probs:\\n\", decode_to_vocab(interv_logits, tokenizer, k=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Natural Text Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = f\"The word \\\"{test_pair['input']}\\\" means\"\n",
    "co, io = fv_intervention_natural_text(sentence, EDIT_LAYER, FV, model, model_config, tokenizer, max_new_tokens=10)\n",
    "\n",
    "\n",
    "print(\"Input Sentence: \", repr(sentence))\n",
    "print(\"GPT-J:\" , repr(tokenizer.decode(co.squeeze())))\n",
    "print(\"GPT-J+FV:\", repr(tokenizer.decode(io.squeeze())), '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
